---
tags: [artificialintelligence, chatbot, vapas, Notebooks/artificialintelligence, virtualagents, trust, aceptance, judgement]
title: 2004060917_La aceptación de la predicción de los algoritmos
created: '2020-04-06T09:19:55.880Z'
modified: '2020-04-06T09:19:55.880Z'
---

# La aceptación de la predicción de los algoritmos

@logg2019_algorithm realizan un trabajo muy convincente con **seis experimentos distintos** y alguna recogida de información complementaria para valorar cómo de fiables consideramos el consejo de los algoritmos frente al consejo de los humanos o nuestro propio consejo.

Un poco sorprendemente, los experimentos confirman que:

> confiamos más en los algoritmos que en los humanos para valorar sus predicciones.

Las excepciones son cuando se comparan con nuestro propio juicio (tendemos a considerarnos mejores que otros juzgando) y cuando el grupo de interés son expertos.

Para valorar en qué medida se aprecian los algoritmos se utiliza una medida llamada WOA: **Weight of Advice**: primero se pide una predicción, después se da el valor del algoritmo, por último, se pide una predicción modificada: ¿cuánto ha cambiado la predicción en función del input recibido?.

Es interesante pensar porqué en este contexto se presentan estos resultados, pero en los resultados de [@luo2019_frontiers](2004041604_preferimos_comprar_personas_chatbot.md) el efecto en ventas del chatbot se desvanecía en cuanto se averiguaba que era un bot. ¿Estamos dispuestos a aceptar la predicción pero no a interactuar con ellos?

@yeomans2019_making también encuentra un efecto similar, comparando la precisión de un algoritmo con el de una persona para recomendar chistes a alguien (incluyendo las recomendaciones de amigos). Su algoritmo resulta ser mejor que las personas eligiendo los chistes, pero los individuos confían menos en él que en una persona.

**Quizás es interesante comparar el consejo en interactuación directa o mediado por un humano**.


## La confianza en el algoritmo depende del tipo de tarea

Sin embargo (@castelo2019_taskdependent)[2004271035_algorithm_type_task.md] encuentran que en general, se **prefiere el consejo humano**, aunque [@castelo2019_taskdependent](2004271035_algorithm_type_task.md) plantean como la confianza en los algoritmos depende del tipo de tarea, siendo menor para tareas subjetivas que para tareas objetivas.

## La resistencia al uso en aplicaciones médica y el sentido de ser "único"

@longoni2019_resistance en un estudio con ¡11! diseños experimentales estudian la aceptación o no de esta tecnología en aplicaciones médicas y muestran como **preferimos el consejo humano al de la inteligencia artificial**.

Exploran las posibles razones detras de este efecto y la percepción de ser único y la "uniqueness neglect", la percepción de que los algoritmos no saben lidiar tan bien como las personas con las características individuales. 

De hecho, se acepta mejor esta teconología cuando en vez de para uno mismo se plantea para su utilización en el individuo medio. Esto puede estar también relacionado con la **subjetividad** ya que la adaptación a un individuo es más subjetiva que la evaluación para el individuo medio. 

También comprueban que se acepta mejor como apoyo a los profesionales, que como sustituto,


## Notas relacionadas:

- [Index](_2003101705_index.md)
- [La confianza inicial en el agente virtual](2004060904_confianza_agentevirtual.md)
- [El tipo de tarea y la interacción con los algoritmos](2004271035_algorithm_type_task.md)
- [Preferimos interactuar con personas que con agentes virtuales](2004041604_preferimos_comprar_personas_chatbot.md)
- [La intención de adopción de agentes virtuales](2004060832_intencion_adopcion_agente_virtual.md)
- [Chatbot y compliance: El efecto "foot-in-the door"](2003241149_chatbots_footinthedoor_y_compliance.md)

--

References:


- Castelo, N., Bos, M. W., & Lehmann, D. R. (2019). Task-Dependent Algorithm Aversion. Journal of Marketing Research, 002224371985178. https://doi.org/10.1177/0022243719851788
- Logg, J. M., Minson, J. A., & Moore, D. A. (2019). Algorithm appreciation: People prefer algorithmic to human judgment. Organizational Behavior and Human Decision Processes, 151(December 2018), 90–103. https://doi.org/10.1016/j.obhdp.2018.12.005
- Longoni, C., Bonezzi, A., & Morewedge, C. K. (2019). Resistance to Medical Artificial Intelligence. Journal of Consumer Research, 46(4), 629–650. https://doi.org/10.1093/jcr/ucz013
