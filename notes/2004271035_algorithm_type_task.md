---
tags: [artificialintelligence, chatbot, vapas, Notebooks/artificialintelligence, virtualagents, task, subjectivity]
title: 2004271035_La adecuación de la IA según el tipo de tarea
created: '2020-04-27T10:35:55.880Z'
modified: '2020-04-27T10:35:55.880Z'
---

# La adecuación de la IA según el tipo de tarea

La inteligencia artificial y los VAPAs pueden ser más o menos adecuados según el tipo de tarea. 

Un factor importante en la aceptación de estos dispositivos es su [utilidad percibida](2004060840_utilidad_percibidad_agentesvirtuales.md) y esta utilidad percibida depende a sí mismo de la variedad de funciones que pueda realizar.

Estos dispositivos pueden utilizarse para una amplia variedad de [tareas](2004110921_tareas_personales_asistentes.md) por lo que cabe plantearse si la utilidad percibida es la misma para todas ellas o depende del tipo de tareas.

Podemos clasificar las tareas en distintas categorías.

## Las tareas según su objetividad/subjetividad

@castelo2019_taskdependent clasifican las tareas según su objetividad/subjetividad, aunque reconocen que la distinción no es unívoca y hablan de objetividad percibida de la tarea. En su definición:

> We define an objective task as one that involves facts that are quantifiable and measurable, compared with subjective tasks, which we define as being open to interpretation and based on personal opinion or intuition. (page 3).

Y plantean como hipótesis que los individuos confían menos en los algoritmos para tareas subjetivas que las objetivas. También plantean que incrementar la "objetividad percibida" de una tarea incrementa el potencial de los algoritmos (por ejemplo, si se describe la tarea como más cuantitativa). Por último, se plantea un posible efecto moderador del parecido a la persona, similar a la [personificación o antropomorfismo](2004060734_antropomorfismo_vapas.md). 

> if the task for which AI is being used is believed to involve affective abilities or qualities, then consumers may be less likely to use AI for that task, relative to tasks that do not involve such abilities or qualities, because AI is believed to be less useful for such tasks. [@castelo2019_blurring page 30]

Plantean seis estudios para contestar a estas cuestiones:

- Estudio 1: qué tareas son subjetivas y cuales objetivas y nivel de confianza con 26 tareas. Se incluye también la "consecuencialidad" de la tarea, que es una medida de riesgo y la familiaridad en el uso. Se usa una escala simple de objetiva versus subjetiva y se confirma que la confianza es mayor para las más objetivas.

- Estudio 2: anuncios en Facebook de recomendador humano y artificial para consejo financiero (objetivo) vs búsqueda pareja (subjetivo). Se estudia directamente el CTR y se confirma que en la tarea subjetiva se confía más en el humano.

- Estudio 3: se manipula el acierto percibido del algoritmo acompañando con reportes de aciertos sugieriendo superioridad, y ven que este efecto es menor en las tareas subjetivas. Para ello se clasifican las tareas según la objetividad que han declarado resultando en:
  - Tareas objetivas: Predict student performance, Predict employee performance, Recommend disease treatment, Drive a car, Diagnose a disease
  - Tareas subjetivas: Predict recidivism, Recommend a movie, Predict personality traits, Predict joke enjoyment

- Estudio 4: trata de confirmar el efecto de incrementar la "objetividad percibida" sugiriendo un análisis cuantitativo. Las tareas son recomendar una película y recomendar una pareja. 

- Estudio 5: confirmación con otro estudio en facebook que manipula la objetividad percibida

- Estudio 6: afectividad similar a la persona del algoritmo. Se manpulan las habilidades afectivas dándoles a leer un texto reafirmativo en ese sentido y en la otra condición un texto contrario. Efectivamente, cuando se piensa que los algoritmos tienen estas habilidades, la confianza en el consejo es mayor.

Este mismo trabajo se presenta en una versión divulgativa en @castelo2019_letthemachine.

[@logg2019_algorithm](2004060917_aceptacion_consejo_algoritmos.md) también incluyen el nivel de subjetividad en su trabajo general sobre aceptación del consejo de los algoritmos, variando el nivel de subjetividad según el experimento, aunque no contrastan situaciones con alta y baja subjetividad.

@dijkstra1998_persuasivenes tienen en cuenta la subjetividad desde una perspectiva más diferente: cómo se perciben las decisiones del algoritmo, comparando el mismo resultado presentado a los sujetos que proviene de un sistema humano o experto. Los resultados muestran que el Sistema Experto se percibe como más objetivo que el humano.

@yeomans2019_making se centra en un contexto subjetivo, la selección de chistes, para comparar la aceptación del consejo de algoritmos, encontrando que, aunque el consejo es mejor que las personas eligiendo los chistes, pero los individuos confían menos en él que en una persona.

## Las tareas según su nivel de riesgo

@castelo2019_taskdependent incluyen en el estudio 1 el nivel de "consecuencialidad" de las tareas. Para ello incluyen simplemente un indicador:
- how consequential versus inconsequential it seemed, using scales from 0 (“not at all”) to 100 (“completely”). 

Encuentran que se confía menos en los algoritmos para las tareas con mayores consecuencias. 

## Las tareas según su componente hedónico versus utilitario

@castelo2019_blurring (gágina 31) también plantean una posible diferencia según el componente hedónico versus utilitario de la tarea, aunque esto no se contrasta en el trabajo. Según su definición:

> Hedonic tasks involve affective, sensory, and aesthetic factors relative to utilitarian tasks which involve more cognitive, instrumental, and functional factors (Dhar and Wertenbroch 2000; Holbrook and Hirschman 1982; Shiv and Fedorikhin 1999).

## Las tareas según su nivel de sociabilidad y de enjoyment

@castelo2019_blurring también menciona de pasada estas dos características de las tareas, sin entrar en más detalles al respecto. Con respecto a la sociabilidad, puede estar relacionada con el [uso en privado o en público](2004070858_uso_privado_publico_asistentes.md) de los asistentes, mientras que las tareas hedónicas pueden estar más relacionadas con el nivel de [disfrute hedónico](2004060858_disfrute_percibido_agentes_virtuales.md) que proporciona una tarea, ya que puede depender más de la perspectiva individual que de la definición de la tarea en sí misma.

## Notas relacionadas

- [Index](_2003101705_index.md)
- [La intención de adopción de agentes virtuales](2004060832_intencion_adopcion_agente_virtual.md)
- [La utilidad percibida de los VAPAS](2004060840_utilidad_percibidad_agentesvirtuales.md)
- [La confianza en los agentes virtuales](2004060904_confianza_agentevirtual.md)
- [La aceptación del consejo de los algoritmos](2004060917_aceptacion_consejo_algoritmos.md)
- [La atención a los anuncios en Facebook](2004180843_atencion_anuncios_facebook_segunamistad.md)
- [El uso en privado y en público de los asistentes virtuales de voz](2004070858_uso_privado_publico_asistentes.md)
- [El disfrute percibido en el uso de los VAPAS](2004060858_disfrute_percibido_agentes_virtuales.md)
- [Los modelos de precios y negocio de los asistentes](2004281216_modelos_precios_asistentes_virtuales.md)

--
References

- Castelo, N., Bos, M. W., & Lehmann, D. R. (2019). Task-Dependent Algorithm Aversion. Journal of Marketing Research, 002224371985178. https://doi.org/10.1177/0022243719851788
- Castelo, N., Bos, M. W., & Lehmann, D. (2019). Let the Machine Decide: When Consumers Trust or Distrust Algorithms. NIM Marketing Intelligence Review, 11(2), 24–29. https://doi.org/10.2478/nimmir-2019-0012
- Castelo, N. (2019). Blurring the Line Between Human and Machine: Marketing Artificial Intelligence. Dissertation. Columbia Business School
- Dijkstra, J. J., Liebrand, W. B. G., & Timminga, E. (1998). Persuasiveness of expert systems. Behaviour & Information Technology, 17(3), 155–163. https://doi.org/10.1080/014492998119526
- Logg, J. M., Minson, J. A., & Moore, D. A. (2019). Algorithm appreciation: People prefer algorithmic to human judgment. Organizational Behavior and Human Decision Processes, 151(December 2018), 90–103. https://doi.org/10.1016/j.obhdp.2018.12.005
- Yeomans, M., Shah, A., Mullainathan, S., & Kleinberg, J. (2019). Making sense of recommendations. Journal of Behavioral Decision Making, 32(4), 403–414. https://doi.org/10.1002/bdm.2118