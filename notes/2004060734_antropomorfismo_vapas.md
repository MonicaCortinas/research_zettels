---
tags: [artificialintelligence, chatbot, vapas, Notebooks/artificialintelligence, virtualagents, antropomorphism]
title: 2004060734_El antropomorfismo de los agentes virtuales
created: '2020-04-06T07:34:55.880Z'
modified: '2020-04-06T07:34:55.880Z'
---

# El antropomorfismo de los agentes virtuales

EL antropomorfismo de un agente virtual indica en qué medida lo consideramos similar a una persona. Se espera que niveles de antropomorfismo altos mejoren la aceptación de los agentes virtuales, ya que los sentimos como más cercanos. Sin embargo, demasiado nivel de antropomorfismo puede generar rechazo (uncanney valley).

@moussawi2020_how definen el antropomorfismo cómo: 

> Anthropomorphism is the act of attributing capacities that are considered distinctly human to non-human agents.

Las pistas de antropomorfismo difieren entre los agentes dependiendo de si tienen [cuerpo o no](2004040921_cuerpo_presencia_fisica_asistentes_virtuales.md)

En el modelo se incluye el **antropomorfismo percibido** que se define como:

> perceived anthropomorphism as the degree to which the users perceive the agent to be human-like based on typically and uniquely human characteristics, such as being fluent, respectful, or funny (uniquely human attributes) and as being friendly, happy or caring (human nature features)

@moussawi2020_how incluyen el antropomorfismo en un modelo de aceptación de asistentes virtuales, con un efecto positivo en las dimensiones **hedónicas** de la interacción:

- el disfrute percibido
- la confianza inicial

Sin embargo, no predicen un efecto en las dimensiones **funcionales**: utilidad percibidad, facilidad percibida de uso.

El antropomorfismo es distinto de la **inteligencia percibida**.

Las dimensiones hedónicas tienen un efecto positivo en la intención de adopción, por lo que se espera que el antropomorfismo **percibido** tenga un efecto positivo en la intención de adopción y así se confirma para el caso de la utilidad percibida, pero no para la facilidad de uso, en un modelo estimado con PLS y una muesta de 179 estudiantes.

El antropomorfismo percibido puede también denominarse "personificación" el grado en el que percibimos que el dispositivo es una persona, lo que está íntimamente relacionado con la capacidad para establecer una [relación con el dispositivo](2004160935_relacion_con_vapas.md). @purington2017_alexa analizan las reviews del Amazon Echo buscando indicadores de que se refieran al dispositivo como una persona, encontrando un uso de pronombres elevado y una mayor personificación cuando se refieren a actividades sociales con el dispositivo. De la misma forma, en el trabajo de @gao2018_alexa se trata de detectar personificación en las reviews de varios dispositivos en amazon y, aunque el análisis tiene bastantes carencias, argumentan encontrar reviews más positivas para aquellas reviews en las que el dispositivo está más "personificado".

### La escala de antropomorfismo percibido

Perceived anthropomorphism adapted from Moussawi and Koufaris (2019). 

- PAnt1 - Siri is able to speak like a human. 
- PAnt2 - Siri can be happy. 
- PAnt3 - Siri is friendly. 
- PAnt4 - Siri is respectful. 
- PAnt5 - Siri is funny. 
- PAnt6 - Siri is caring. Perceived

@steinhoff2019_online en un artículo teórico en JAMS explican las implicaciones de los VAPAS para el marketing de relaciones y consideran el antropomorfismo una característica que puede mejorar la relación con los chatbots.

- Antropomorfismo: 
> *"Through chatbots, virtual assistants, or embodied virtual agents on their websites, firms seek to make customer interactions seem more interpersonal, real-time, and tangible (Liu et al. 2009;Mimounetal. 2012). Often companies equip their virtual service personnel with humanoid traits (e.g., looks, voice, names) to encourage customers to bond with them (van Doorn et al. 2017). "*  


## Los efectos negativos del antropomorfismo

Aunque en el enfoque CASA o en la idea de personificación, un antropomorfismo mayor conlleva efectos positivos para la adopción de estos dispositivos, otra literatura predice que un antropomorfismo mayor puede generar sensación de incomodidad. Según Castelo (2019):

> "the effects of cognitive human-likeness on comfort may be non-linear, with initial increases preserving control with the technology, but further increases creating perceived threats and discomfort even as the technology becomes more useful" @castelo2019_blurring, page 22

## La "affective human-likeness" del algoritmo. 

[@castelo2019_taskdependent](2004271035_algorithm_type_task.md) plantean un efecto moderador del "parecido a la persona en cuanto a las capacidades afectivas" en la aceptación del consejo de los algoritmos. Los algoritmos que se percibe tienen unas capacidades afectivas mayores se pueden percibir como mejores para tareas subjetivas y mejorando la confianza a pesar de que puedan generar incomididad. 

@castelo2019_taskdependent mencionan dos dimensiones distintas en este parecido:

- habilidades cognitivas
- habilidades afectivas también llamadas de "agencia", o de "naturaleza humana"

En el estudio 6 de ese trabajo se manipula esta dimensión de habilidades afectivas dándoles a leer un texto reafirmativo en ese sentido y en la otra condición un texto contrario. Efectivamente, cuando se piensa que los algoritmos tienen estas habilidades, la confianza en el consejo es mayor.

## El antropomorfismo en los chatbots

En el trabajo de @adam2020_AIbased: [Chatbots: Antropomorfismo y Presencia Social](2003241127_chatbotsycustomercompliance.md) se muestra que los chatbots que imitan el comportamiento más social de las personas tienen una mejor acogida.

## Cuestiones abiertas sobre el antropomorfismo

Así, según @steinhoff2019_online las preguntas abiertas son:

- Los sentimientos de gratitud pueden ser más pronunciados si se refieren a una sola persona relevante (por ejemplo un charbot) que a una empresa anónima global  (Palmatier et al. 2009). 

- Uncanny valley (Mori et al. 2012): ¿existe realmente, en qué condiciones los agentes pueden generar incomodidad? (Gray and Wegner 2012; MacDorman 2005)

- Expectativas: si no consiguen estar a la altura de la "humanidad" esperada pueden generar decepción por no coincidir con la experiencia esperada (DiSalvo and Gemperle 2003; Mori et al. 2012) y se pueden personificar más en el agente los fallos generales de la tecnología (Serenko 2007). 

- En algunos contextos, un agente virtual puede ser más confiable que una persona para tratar cuestiones que puedan resultar demasiado embarazosas o intimas y pueden resultar preferibles para estas tareas. 

## Notas relacionadas

- [Index](_2003101705_index.md)
- [La intención de adopción de agentes virtuales](2004060832_intencion_adopcion_agente_virtual.md)
- [Chatbots: Antropomorfismo y Presencia Social](2003241127_chatbotsycustomercompliance.md)
- [Nomenclatura en asistentes virtuales](2004030718_nombresasistentesvirtuales.md)
- [El cuerpo y la presencia de los asistentes](2004040921_cuerpo_presencia_fisica_asistentes_virtuales.md)
- [La inteligencia percibida de los agentes virtuales](2004060750_inteligencia_percibida_agentes_virtuales.md)
- [Los usos de los agentes virtuales](2004060821_usos_virtual_agents_sistemas_duales.md)
- [La interactuación por voz frente a la de tacto](2004051647_effect_voice_interactions.md)
- [El tipo de lenguaje de los asistentes](2004051732_tipo_lenguaje_asistentes.md)
- [Chatbot y compliance: El efecto "foot-in-the door"](2003241149_chatbots_footinthedoor_y_compliance.md)
- [Chatbots: El aprendizaje tutorizado interactivo en la educación del futuro](2003101700_aprendizaje_interactivo_educacion_futuro.md)
- [Análisis de patentes sobre chatbots en los últimos 20 años](2003250911_analisistextopatentesparachatbots.md)
- [Los usos profesionales de los agentes virtuales](2004081151_usos_profesionales_vapas.md)

--

Referencias 


- Adam, M., Wessel, M., & Benlian, A. (2020). AI-based chatbots in customer service and their effects on user compliance. Electronic Markets, 1–19. https://doi.org/10.1007/s12525-020-00414-7
- Castelo, N. (2019). Blurring the Line Between Human and Machine: Marketing Artificial Intelligence.
- Gao, Y., Pan, Z., Wang, H., & Chen, G. (2018). Alexa, My Love: Analyzing Reviews of Amazon Echo. In L. Wang, G and Han, Q and Bhuiyan, MZA and Ma, X and Loulergue, F and Li, P and Roveri, M and Chen (Ed.), 2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI) (pp. 372–380). https://doi.org/10.1109/SmartWorld.2018.00094
- Moussawi, S., Koufaris, M., & Benbunan-Fich, R. (2020). How perceptions of intelligence and anthropomorphism affect adoption of personal intelligent agents. Electronic Markets. https://doi.org/10.1007/s12525-020-00411-w
- Purington, A., Taft, J. G., Sannon, S., Bazarova, N. N., & Taylor, S. H. (2017). “Alexa is my new BFF”: Social Roles, User Satisfaction, and Personification of the Amazon Echo. Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems - CHI EA ’17, 2853–2859. https://doi.org/10.1145/3027063.3053246
- Steinhoff, L., Arli, D., Weaven, S., & Kozlenkova, I. V. (2019). Online relationship marketing. Journal of the Academy of Marketing Science, 47(3), 369–393. https://doi.org/10.1007/s11747-018-0621-6